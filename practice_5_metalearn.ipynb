{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32618f7",
   "metadata": {},
   "source": [
    "# Practice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f2323",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58b0548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "#Cross validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score)\n",
    "# to import the cancer patients dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "#Suport vector machine\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "#Decicion trees\n",
    "from sklearn import tree\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#PCA\n",
    "# to standardize the features\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# to apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "#Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#Libraries for stacking\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bdb4a",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa9e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables, target = load_breast_cancer(return_X_y=True,as_frame=True) #load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4b7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = dataframe of features variables\n",
    "#target= target variable (categorical)\n",
    "features=variables.iloc[0:,[0,1,2,3,4,5,6,7,8,9]]\n",
    "target1=pd.DataFrame(target)\n",
    "target1.rename({'target': 'Diagnosis'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29c33ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  \n",
       "0                   0.07871  \n",
       "1                   0.05667  \n",
       "2                   0.05999  \n",
       "3                   0.09744  \n",
       "4                   0.05883  \n",
       "..                      ...  \n",
       "564                 0.05623  \n",
       "565                 0.05533  \n",
       "566                 0.05648  \n",
       "567                 0.07016  \n",
       "568                 0.05884  \n",
       "\n",
       "[569 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2a1455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Diagnosis\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "..         ...\n",
       "564          0\n",
       "565          0\n",
       "566          0\n",
       "567          0\n",
       "568          1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca4f2b",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8ad8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbdc48a",
   "metadata": {},
   "source": [
    "## Aplying meta-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38a40d",
   "metadata": {},
   "source": [
    "### Boosting: \n",
    "This algorithm builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the loss function, e.g. binary or multiclass log loss. Binary classification is a special case where only a single regression tree is induced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d68f0296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[42  3]\n",
      " [ 2 66]]\n",
      "True negative: 42\n",
      "False negative: 2\n",
      "True positive: 66\n",
      "False positive: 3\n",
      "Accuracy: 0.9557522123893806\n",
      "Sensitivity: 0.9705882352941176\n",
      "Specificity: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Boosting with default values\n",
    "GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2,max_depth=1, random_state=0)\n",
    "y_prediction = cross_val_predict(GBC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa98773",
   "metadata": {},
   "source": [
    "##### Trying to better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e59e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[41  4]\n",
      " [ 1 67]]\n",
      "True negative: 41\n",
      "False negative: 1\n",
      "True positive: 67\n",
      "False positive: 4\n",
      "Accuracy: 0.9557522123893806\n",
      "Sensitivity: 0.9852941176470589\n",
      "Specificity: 5.0\n"
     ]
    }
   ],
   "source": [
    "#Boosting with exponential loss and he function to measure the quality of a split is sqared error\n",
    "GBC = GradientBoostingClassifier(loss='exponential',n_estimators=200, \n",
    "                                 learning_rate=1.0,max_depth=1, criterion='squared_error',random_state=0)\n",
    "y_prediction = cross_val_predict(GBC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7df015",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "| Boosting (default values)| 0.95 |  0.97 | 4 |\n",
    "| Boosting (loss=exponential) | 0.95 | 0.98 | 5 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4bb351",
   "metadata": {},
   "source": [
    "### Baggin:\n",
    "Bagging is an ensemble machine learning algorithm that combines the predictions from many decision trees. It is easy to implement with few key hyperparameters and sensible heuristics for configuring these hyperparameters. Bagging performs well in general and provides the basis for a whole field of ensemble of decision tree algorithms such as the popular random forest and extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "377303ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[30 15]\n",
      " [ 2 66]]\n",
      "True negative: 30\n",
      "False negative: 2\n",
      "True positive: 66\n",
      "False positive: 15\n",
      "Accuracy: 0.8495575221238938\n",
      "Sensitivity: 0.9705882352941176\n",
      "Specificity: 16.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with default values\n",
    "BAGGIN = BaggingClassifier(estimator=SVC(),n_estimators=10, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c56f1",
   "metadata": {},
   "source": [
    "##### Trying to better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1587086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[40  5]\n",
      " [ 5 63]]\n",
      "True negative: 40\n",
      "False negative: 5\n",
      "True positive: 63\n",
      "False positive: 5\n",
      "Accuracy: 0.911504424778761\n",
      "Sensitivity: 0.9264705882352942\n",
      "Specificity: 6.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with Decision Tree estimator, The function to measure the quality of a split is entropy\n",
    "d_tree = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "BAGGIN = BaggingClassifier(estimator=d_tree,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0bf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[41  4]\n",
      " [ 2 66]]\n",
      "True negative: 41\n",
      "False negative: 2\n",
      "True positive: 66\n",
      "False positive: 4\n",
      "Accuracy: 0.9469026548672567\n",
      "Sensitivity: 0.9705882352941176\n",
      "Specificity: 5.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with Naive Bayes estimator\n",
    "gnb = GaussianNB()\n",
    "BAGGIN = BaggingClassifier(estimator=gnb,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19211fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Confusion matrix: [[ 0 45]\n",
      " [ 1 67]]\n",
      "True negative: 0\n",
      "False negative: 1\n",
      "True positive: 67\n",
      "False positive: 45\n",
      "Accuracy: 0.5929203539823009\n",
      "Sensitivity: 0.9852941176470589\n",
      "Specificity: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2319/1670565986.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  SPE=TN/TN+FP\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with Bernoulli Naive Bayes estimator\n",
    "BNB= BernoulliNB()\n",
    "BAGGIN = BaggingClassifier(estimator=BNB,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3b88a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[36  9]\n",
      " [ 3 65]]\n",
      "True negative: 36\n",
      "False negative: 3\n",
      "True positive: 65\n",
      "False positive: 9\n",
      "Accuracy: 0.8938053097345132\n",
      "Sensitivity: 0.9558823529411765\n",
      "Specificity: 10.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with KNeighbors Classifier estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree')\n",
    "BAGGIN = BaggingClassifier(estimator=knn,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdc2049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[40  5]\n",
      " [ 5 63]]\n",
      "True negative: 40\n",
      "False negative: 5\n",
      "True positive: 63\n",
      "False positive: 5\n",
      "Accuracy: 0.911504424778761\n",
      "Sensitivity: 0.9264705882352942\n",
      "Specificity: 6.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with support vector machine estimator, linear kernel\n",
    "SVM = svm.SVC(kernel='linear', C=1)\n",
    "BAGGIN = BaggingClassifier(estimator=SVM,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdce5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[31 14]\n",
      " [ 2 66]]\n",
      "True negative: 31\n",
      "False negative: 2\n",
      "True positive: 66\n",
      "False positive: 14\n",
      "Accuracy: 0.8584070796460177\n",
      "Sensitivity: 0.9705882352941176\n",
      "Specificity: 15.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with support vector machine estimator polynomial kernel\n",
    "SVM = svm.SVC(kernel='poly', C=1)\n",
    "BAGGIN = BaggingClassifier(estimator=SVM,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2233fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[40  5]\n",
      " [ 2 66]]\n",
      "True negative: 40\n",
      "False negative: 2\n",
      "True positive: 66\n",
      "False positive: 5\n",
      "Accuracy: 0.9380530973451328\n",
      "Sensitivity: 0.9705882352941176\n",
      "Specificity: 6.0\n"
     ]
    }
   ],
   "source": [
    "#Baggin clasification with support vector machine estimator, SVC LINEAR kernel\n",
    "SVM =svm.LinearSVC(C=1, max_iter=10000, dual=\"auto\")\n",
    "BAGGIN = BaggingClassifier(estimator=SVM,n_estimators=100, random_state=0)\n",
    "y_prediction = cross_val_predict(BAGGIN, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e4fcc",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "| Baggin (default values) | 0.84 |  0.97 | 16 |\n",
    "| Baggin (Decision Tree, loss=entropy) | 0.91 | 0.92 | 6 |\n",
    "| Baggin (Gaussian Naive Bayes) | 0.94 |  0.97 | 5 |\n",
    "| Baggin (Bernoulli Naive Bayes | 0.59 |  0.98 | 5 |\n",
    "| Baggin (K Neighbors) | 0.89 |  0.95 | 10 |\n",
    "| Baggin (SVM linear kernel) | 0.91 |  0.92 | 6 |\n",
    "| Baggin (linear SVC) | 0.93 |  0.97 | 6 |\n",
    "| Baggin (SVM polynomial kernel) | 0.85 |  0.97 | 6 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00826f3",
   "metadata": {},
   "source": [
    "### Stacking:\n",
    "Stack of estimators with a final classifier. Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator. Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88d59305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144736842105263"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stacking clasification with Random Forest, linear SVC and logistic regresion. \n",
    "estimators=[\n",
    "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     ('svr', make_pipeline(StandardScaler(),\n",
    "     LinearSVC(dual=\"auto\", random_state=42)))]\n",
    "#Creating the model\n",
    "STC=StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "STC.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014de0d8",
   "metadata": {},
   "source": [
    "##### Trying to better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e38d1235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[37  8]\n",
      " [ 3 65]]\n",
      "True negative: 37\n",
      "False negative: 3\n",
      "True positive: 65\n",
      "False positive: 8\n",
      "Accuracy: 0.9026548672566371\n",
      "Sensitivity: 0.9558823529411765\n",
      "Specificity: 9.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking clasification with Random Forest, poly SVM and logistic regresion. \n",
    "\n",
    "#Weak learners\n",
    "estimators=[\n",
    "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     ('svm',svm.SVC(kernel='poly', C=1) ,\n",
    "     )]\n",
    "#Creating the model\n",
    "STC=StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "y_prediction = cross_val_predict(STC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2720087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[35 10]\n",
      " [ 7 61]]\n",
      "True negative: 35\n",
      "False negative: 7\n",
      "True positive: 61\n",
      "False positive: 10\n",
      "Accuracy: 0.8495575221238938\n",
      "Sensitivity: 0.8970588235294118\n",
      "Specificity: 11.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking clasification with Random Forest, poly SVM, Gaussian Naive Bayes, and logistic regresion. \n",
    "\n",
    "#Weak learners\n",
    "estimators=[\n",
    "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     ('svm',svm.SVC(kernel='poly', C=1) ,\n",
    "     GaussianNB())]\n",
    "#Creating the model\n",
    "STC=StackingClassifier(estimators=estimators, final_estimator=tree.DecisionTreeClassifier(criterion='entropy'))\n",
    "\n",
    "y_prediction = cross_val_predict(STC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dd74e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[39  6]\n",
      " [ 4 64]]\n",
      "True negative: 39\n",
      "False negative: 4\n",
      "True positive: 64\n",
      "False positive: 6\n",
      "Accuracy: 0.911504424778761\n",
      "Sensitivity: 0.9411764705882353\n",
      "Specificity: 7.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking clasification with Random Forest, poly SVM, Gaussian Naive Bayes.\n",
    "\n",
    "#Weak learners\n",
    "estimators=[\n",
    "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     ('svm',svm.SVC(kernel='rbf', C=1) ,\n",
    "     GaussianNB())]\n",
    "#Creating the model\n",
    "STC=StackingClassifier(estimators=estimators, final_estimator=GaussianNB())\n",
    "\n",
    "y_prediction = cross_val_predict(STC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0741b",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "| Stacking (Random Forest, linear SVM, logistic regresion) | 0.90 |  0.95 | 9 |\n",
    "| Stacking (Random Forest, poly SVM, Gaussian Naive Bayes, logistic regresion) | 0.84 | 0.89 | 11 |\n",
    "| Stacking (Random Forest, poly SVM, Gaussian Naive Bayes, tree decision) | 0.91 |  0.94 | 7 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c52798",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "A random forest classifier, is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da70cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[39  6]\n",
      " [ 5 63]]\n",
      "True negative: 39\n",
      "False negative: 5\n",
      "True positive: 63\n",
      "False positive: 6\n",
      "Accuracy: 0.9026548672566371\n",
      "Sensitivity: 0.9264705882352942\n",
      "Specificity: 7.0\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with default values\n",
    "# Creating the model\n",
    "RFC = RandomForestClassifier(random_state=0)\n",
    "\n",
    "y_prediction = cross_val_predict(RFC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19933792",
   "metadata": {},
   "source": [
    "##### Trying to better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a0264a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[39  6]\n",
      " [ 4 64]]\n",
      "True negative: 39\n",
      "False negative: 4\n",
      "True positive: 64\n",
      "False positive: 6\n",
      "Accuracy: 0.911504424778761\n",
      "Sensitivity: 0.9411764705882353\n",
      "Specificity: 7.0\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with other parameters\n",
    "# Creating the model\n",
    "RFC = RandomForestClassifier(criterion='entropy',max_depth=4,random_state=0,max_features='log2')\n",
    "\n",
    "y_prediction = cross_val_predict(RFC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a41ce570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[39  6]\n",
      " [ 3 65]]\n",
      "True negative: 39\n",
      "False negative: 3\n",
      "True positive: 65\n",
      "False positive: 6\n",
      "Accuracy: 0.9203539823008849\n",
      "Sensitivity: 0.9558823529411765\n",
      "Specificity: 7.0\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with other parameters\n",
    "# Creating the model\n",
    "RFC = RandomForestClassifier(criterion='log_loss',max_depth=10,random_state=2,max_features=None)\n",
    "\n",
    "y_prediction = cross_val_predict(RFC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5eef6",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "| Random Forest (default values) | 0.90 |  0.92 | 7 |\n",
    "| Random Forest (criterion=entropy) | 0.91 | 0.94 | 7 |\n",
    "| Random Forest (criterion=log loss) | 0.92 |  0.95 | 7 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff11862",
   "metadata": {},
   "source": [
    "###  AdaBoost:\n",
    "\n",
    "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b3549ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[41  4]\n",
      " [ 1 67]]\n",
      "True negative: 41\n",
      "False negative: 1\n",
      "True positive: 67\n",
      "False positive: 4\n",
      "Accuracy: 0.9557522123893806\n",
      "Sensitivity: 0.9852941176470589\n",
      "Specificity: 5.0\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with default values\n",
    "# Creating the model\n",
    "ABC=AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c16d4",
   "metadata": {},
   "source": [
    "##### trying to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49ae4ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 0 1]\n",
      "Confusion matrix: [[39  6]\n",
      " [ 6 62]]\n",
      "True negative: 39\n",
      "False negative: 6\n",
      "True positive: 62\n",
      "False positive: 6\n",
      "Accuracy: 0.8938053097345132\n",
      "Sensitivity: 0.9117647058823529\n",
      "Specificity: 7.0\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with Linear SVC estimator\n",
    "# Creating the model\n",
    "SVM =svm.LinearSVC(C=1, max_iter=10000, dual=\"auto\")\n",
    "ABC=AdaBoostClassifier(estimator=SVM, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87ee6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 1]\n",
      "Confusion matrix: [[40  5]\n",
      " [ 8 60]]\n",
      "True negative: 40\n",
      "False negative: 8\n",
      "True positive: 60\n",
      "False positive: 5\n",
      "Accuracy: 0.8849557522123894\n",
      "Sensitivity: 0.8823529411764706\n",
      "Specificity: 6.0\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with decision tree estimator\n",
    "# Creating the model\n",
    "d_tree = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "ABC=AdaBoostClassifier(estimator=d_tree, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8deeac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 0 0]\n",
      "Confusion matrix: [[42  3]\n",
      " [ 5 63]]\n",
      "True negative: 42\n",
      "False negative: 5\n",
      "True positive: 63\n",
      "False positive: 3\n",
      "Accuracy: 0.9292035398230089\n",
      "Sensitivity: 0.9264705882352942\n",
      "Specificity: 4.0\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with gaussian naive bayes\n",
    "# Creating the model\n",
    "gnb = GaussianNB()\n",
    "ABC=AdaBoostClassifier(estimator=gnb, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8f8b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Confusion matrix: [[ 0 45]\n",
      " [ 0 68]]\n",
      "True negative: 0\n",
      "False negative: 0\n",
      "True positive: 68\n",
      "False positive: 45\n",
      "Accuracy: 0.6017699115044248\n",
      "Sensitivity: 1.0\n",
      "Specificity: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2319/2923798029.py:25: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  SPE=TN/TN+FP\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with Bernoulli Naive Bayes\n",
    "# Creating the model\n",
    "BNB= BernoulliNB()\n",
    "ABC=AdaBoostClassifier(estimator=BNB, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(BNB, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "778c124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1]\n",
      "Confusion matrix: [[21 24]\n",
      " [ 0 68]]\n",
      "True negative: 21\n",
      "False negative: 0\n",
      "True positive: 68\n",
      "False positive: 24\n",
      "Accuracy: 0.7876106194690266\n",
      "Sensitivity: 1.0\n",
      "Specificity: 25.0\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with SVM kernel='poly'\n",
    "# Creating the model\n",
    "SVM = svm.SVC(kernel='poly', C=1)\n",
    "ABC=AdaBoostClassifier(estimator=SVM, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7bb22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Confusion matrix: [[ 0 45]\n",
      " [ 0 68]]\n",
      "True negative: 0\n",
      "False negative: 0\n",
      "True positive: 68\n",
      "False positive: 45\n",
      "Accuracy: 0.6017699115044248\n",
      "Sensitivity: 1.0\n",
      "Specificity: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2319/3080983698.py:25: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  SPE=TN/TN+FP\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with SVM kernel='rbf'\n",
    "# Creating the model\n",
    "SVM = svm.SVC(kernel='rbf', C=1)\n",
    "ABC=AdaBoostClassifier(estimator=SVM, n_estimators=100, random_state=0,algorithm='SAMME')\n",
    "\n",
    "y_prediction = cross_val_predict(ABC, x_train, y_train, cv=10)\n",
    "print('Predicted values:',y_prediction)\n",
    "\n",
    "#Metrics\n",
    "#Confusion matrix\n",
    "CM=confusion_matrix(y_train, y_prediction)\n",
    "#true negative\n",
    "TN=CM[0,0]\n",
    "#false negative\n",
    "FN=CM[1,0]\n",
    "#true positive\n",
    "TP=CM[1,1]\n",
    "#false positive\n",
    "FP=CM[0,1]\n",
    "#Accuracy \n",
    "accuracy=accuracy_score(y_train, y_prediction)\n",
    "#Sensitivity\n",
    "SEN=TP/(TP+FN)\n",
    "#Specificity\n",
    "SPE=TN/TN+FP\n",
    "\n",
    "print('Confusion matrix:',CM)\n",
    "print('True negative:',TN)\n",
    "print('False negative:',FN)\n",
    "print('True positive:',TP)\n",
    "print('False positive:',FP)\n",
    "\n",
    "print('Accuracy:',accuracy) \n",
    "print('Sensitivity:',SEN)\n",
    "print('Specificity:',SPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b35d3",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "| Adaboost (default values) | 0.95 |  0.98 | 5 |\n",
    "| Adaboost (linear SVC) | 0.91 | 0.92 | 6 |\n",
    "| Adaboost (Gaussian Naive Bayes) | 0.92 |  0.92 | 4 |\n",
    "| Adaboost (Bernoulli Naive Bayes | 0.60 |  1 | x |\n",
    "| Adaboost (decision tree entropy) | 0.88 |  0.88 | 6 |\n",
    "| Adaboost (linear SVC) | 0.89 |  0.91 | 7 |\n",
    "| Adaboost (SVM polynomial kernel) | 0.78 |  1 | 25 |\n",
    "| Adaboost (SVM RBF kernel) | 0.60 | 1 | x |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8a259",
   "metadata": {},
   "source": [
    "## The best classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c6f0f",
   "metadata": {},
   "source": [
    "| Model | Accuracy | Sensitivity | Specificity |\n",
    "| --- | --- | --- | --- |\n",
    "|     |     | Meta ensamble |     |\n",
    "| Adaboost (default values) | 0.95 |  0.98 | 5 |\n",
    "| Random Forest (criterion=log loss) | 0.92 |  0.95 | 7 |\n",
    "| Stacking (Random Forest, poly SVM, Gaussian Naive Bayes, tree decision) | 0.91 |  0.94 | 7 |\n",
    "| Baggin (Gaussian Naive Bayes) | 0.94 |  0.97 | 5 |\n",
    "| Boosting (loss=exponential) | 0.95 | 0.98 | 5 |\n",
    "|     |     | Weak learners |     |\n",
    "| Suport vector machine | 0.91 |  0.92 | 6 |\n",
    "| Decision Trees | 0.89 | 0.89 | 6 |\n",
    "| Naive Bayes | 0.94 |  0.97 | 5 |\n",
    "| K Neighbors Classifier | 0.88 |  0.94 | 10 |\n",
    "| Naive Bayes (PCA) | 0.94 |  0.95 | 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84376e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "For this case, the best classfiers were Adaboost and Boosting, because the metrics show a better classification and prediction for the target variables he was the diagnosis, which can be a cancer malignan (0) or benignin (1), even better than the weak learner Naive Bayes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
