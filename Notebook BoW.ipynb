{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d98e2db-8519-4cd8-9f75-9e65331585a1",
   "metadata": {},
   "source": [
    "# Notebook ICD - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bea34-06dd-4b57-90da-dce66eeedabf",
   "metadata": {},
   "source": [
    "Install libraries via terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582ef0ff-9295-4337-89ee-764fe81c0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy\n",
    "#pip install nltk\n",
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a1956-9666-48c5-98a5-2cbb514c22ef",
   "metadata": {},
   "source": [
    "Importing necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ce4c060-b967-4856-b7cf-b6ea32740ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy as spc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d0bc4-caab-43b2-b791-7a903f2a67f6",
   "metadata": {},
   "source": [
    "## Datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f38d8f-f3e8-4bae-8afe-b74fd140ae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESAS COSAS Y OTRAS PUEDEN PASAR POR MANTENER A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28: te amodio, odio a la perra de tu amiga per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@LaDivinaDiva Callate maldita perra. O seguro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MarysabelPuerto Mejor callate cara de puta o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@xarita327 @TRIKYHUMOR @yonier2012 @casTa1326 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@CocotePR @ashleyhonohan callate puta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y el inmigrante recibe ayuda del rico Estado l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>De los moros no se puede esperar nada bueno, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>¿Por que si a una mujer le pegan un tiro en la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analicemos esto: ¿Si te pones unos shorts así,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"See... Tal vez les recordo como Peron protegi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PIETRAPIERCE STORY: PURS SANGS ARABES STARS DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>¿Qué dice este de frivolizar el acoso escolar?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#Suiza  retira el permiso a 189 refugiados que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hoy quiero denunciaaaaaaar A LA GENTE PUTO GUA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Redomicilie su sociedad offshore en Emiratos Á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@hermanntertsch Basta! Poned pie en pared a ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SEMANA DE LA JUVENTUD. TORNEO FUTBOL7  / FUTBO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@lNeko_ @xTiko98 Callate y metete party de una...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cuántos inmigrantes creemos que hay, y cuántos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   ESAS COSAS Y OTRAS PUEDEN PASAR POR MANTENER A...\n",
       "1   28: te amodio, odio a la perra de tu amiga per...\n",
       "2   @LaDivinaDiva Callate maldita perra. O seguro ...\n",
       "3   @MarysabelPuerto Mejor callate cara de puta o ...\n",
       "4   @xarita327 @TRIKYHUMOR @yonier2012 @casTa1326 ...\n",
       "5               @CocotePR @ashleyhonohan callate puta\n",
       "6   Y el inmigrante recibe ayuda del rico Estado l...\n",
       "7   De los moros no se puede esperar nada bueno, y...\n",
       "8   ¿Por que si a una mujer le pegan un tiro en la...\n",
       "9   Analicemos esto: ¿Si te pones unos shorts así,...\n",
       "10  \"See... Tal vez les recordo como Peron protegi...\n",
       "11  PIETRAPIERCE STORY: PURS SANGS ARABES STARS DE...\n",
       "12  ¿Qué dice este de frivolizar el acoso escolar?...\n",
       "13  #Suiza  retira el permiso a 189 refugiados que...\n",
       "14  Hoy quiero denunciaaaaaaar A LA GENTE PUTO GUA...\n",
       "15  Redomicilie su sociedad offshore en Emiratos Á...\n",
       "16  @hermanntertsch Basta! Poned pie en pared a ta...\n",
       "17  SEMANA DE LA JUVENTUD. TORNEO FUTBOL7  / FUTBO...\n",
       "18  @lNeko_ @xTiko98 Callate y metete party de una...\n",
       "19  Cuántos inmigrantes creemos que hay, y cuántos..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('df.csv',usecols=[1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace6213-b9e5-4dde-80f8-cffede8fc3b7",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72533121-a276-4248-9cd1-71bfdc4ce66f",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2afad44f-9233-4584-9e43-5cad07ef213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esas cosas y otras pueden pasar por mantener a la inmigracion ilegal en españa y no expulsarlos no  la agresión de los manteros a un turista pone a colau en un aprieto  vía ',\n",
       " ' te amodio odio a la perra de tu amiga pero tú eres mi vida tijerazo',\n",
       " ' callate maldita perra o seguro eres un pobre marico detras de un user femenino chavista colaborador',\n",
       " ' mejor callate cara de puta o reputa como tu madre se nota que te hacen falta estos ',\n",
       " '       cállate puta',\n",
       " '  callate puta',\n",
       " 'y el inmigrante recibe ayuda del rico estado ladrón que se olvida de los nacionales mientras nos viola y mata pintada con una verdad a medias ',\n",
       " 'de los moros no se puede esperar nada bueno y esto te lo dicen los propios árabes que también han luchado contra ellos      ',\n",
       " 'por que si a una mujer le pegan un tiro en la cabeza dura tres dias en morirse porque a los tres dias la bala encuentra el cerebro',\n",
       " 'analicemos esto si te pones unos shorts así en la calle qué esperas que te digan acoso o provocación ',\n",
       " 'see tal vez les recordo como peron protegio a eichmann y cientos de nazis o les conto a los arabes el chiste del araba que se lo garcho un camello ',\n",
       " 'pietrapierce story purs sangs arabes stars des festivites a agar el m ',\n",
       " 'qué dice este de frivolizar el acoso escolar por favor queréis dejar de decir semejantes tonterías ',\n",
       " '  retira el permiso a  refugiados que fueron de vacaciones a sus países    vía ',\n",
       " 'hoy quiero denunciaaaaaaar a la gente puto guarra que huele a sudor y chorizo y se sube al bus dejando a tol mundo ko shame on you ',\n",
       " 'redomicilie su sociedad offshore en emiratos árabes unidos ',\n",
       " ' basta poned pie en pared a tanta provocación y cortad la humillación de estos cuatro hijos de perra',\n",
       " 'semana de la juventud torneo futbol   futbol  categoria cadete equipos inscritos los yogurines la elite rayo donbenitense los negratas fuenlabrada minato de kiev los josewifakers voolka ',\n",
       " '  callate y metete party de una puta vez',\n",
       " 'cuántos inmigrantes creemos que hay y cuántos hay en realidad ciudadanos de un lugar llamado mundo ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to clean data\n",
    "def limpieza_datos(oracion):\n",
    "    oracion = oracion.lower()\n",
    "    oracion = re.sub(r\"@\\S+\", \"\", oracion)  # Eliminar menciones a usuarios\n",
    "    oracion = re.sub(\"http[s]?\\://\\S+\", \"\", oracion)  # Eliminar enlaces\n",
    "    oracion = re.sub(r\"#\\S+\", \"\", oracion)  # Eliminar hashtags\n",
    "    oracion = re.sub(r\"[0-9]\", \"\", oracion)  # Eliminar números\n",
    "    oracion = re.sub(r\"(\\(.*\\))|(\\[.*\\])\", \"\", oracion)  # Eliminar paréntesis y corchetes\n",
    "    oracion = re.sub(r\"\\n\", \"\", oracion)  # Eliminar caracteres de nueva línea\n",
    "    oracion = re.sub(r\"(http[s]?\\://\\S+)|([\\[\\(].*[\\)\\]])|([#@]\\S+)|\\n\", \"\", oracion)  # Eliminar varios patrones\n",
    "    oracion = re.sub(r\"(\\.)|(,)\", \"\", oracion)  # Eliminar puntos y comas\n",
    "    oracion = re.sub(r\"[¡!]\", \"\", oracion)  # Eliminar signos de admiración \n",
    "    oracion = re.sub(r\"[¿?]\", \"\", oracion)  # Eliminar signos de exclamación\n",
    "    oracion = re.sub(r\"[*]\", \"\", oracion) #eliminar asteriscos\n",
    "    oracion = re.sub(r\"[\\\"]\", \"\", oracion) #eliminar doble comilla\n",
    "    oracion = re.sub(r\"[:]\", \"\", oracion) #elimnar dos puntos\n",
    "    oracion=re.sub(r\"[-]\",\"\",oracion) #eliminar guion\n",
    "    oracion=re.sub(r\"[\\/]\",\"\",oracion) #eliminar diagonal\n",
    "    return oracion\n",
    "\n",
    "\n",
    "\n",
    "lista_limpia=[] #A list where we keep de clean data\n",
    "n=len(df) #Number of iterations\n",
    "a=df.iloc[10,0]\n",
    "limpieza_datos(a)\n",
    "for i in range(0,n,1):\n",
    "    a=limpieza_datos(df.iloc[i,0])\n",
    "    lista_limpia.append(a)\n",
    "lista_limpia    \n",
    "#datos_limpios={'tweets':lista}\n",
    "#df_limpio=pd.DataFrame(datos_limpios)\n",
    "#df_limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20449-7603-4d01-9866-6be0fbf0063c",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86a798d9-a52d-41bf-80b6-4d36808cee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['esas',\n",
       "  'cosas',\n",
       "  'y',\n",
       "  'otras',\n",
       "  'pueden',\n",
       "  'pasar',\n",
       "  'por',\n",
       "  'mantener',\n",
       "  'a',\n",
       "  'la',\n",
       "  'inmigracion',\n",
       "  'ilegal',\n",
       "  'en',\n",
       "  'españa',\n",
       "  'y',\n",
       "  'no',\n",
       "  'expulsarlos',\n",
       "  'no',\n",
       "  'la',\n",
       "  'agresión',\n",
       "  'de',\n",
       "  'los',\n",
       "  'manteros',\n",
       "  'a',\n",
       "  'un',\n",
       "  'turista',\n",
       "  'pone',\n",
       "  'a',\n",
       "  'colau',\n",
       "  'en',\n",
       "  'un',\n",
       "  'aprieto',\n",
       "  'vía'],\n",
       " ['te',\n",
       "  'amodio',\n",
       "  'odio',\n",
       "  'a',\n",
       "  'la',\n",
       "  'perra',\n",
       "  'de',\n",
       "  'tu',\n",
       "  'amiga',\n",
       "  'pero',\n",
       "  'tú',\n",
       "  'eres',\n",
       "  'mi',\n",
       "  'vida',\n",
       "  'tijerazo'],\n",
       " ['callate',\n",
       "  'maldita',\n",
       "  'perra',\n",
       "  'o',\n",
       "  'seguro',\n",
       "  'eres',\n",
       "  'un',\n",
       "  'pobre',\n",
       "  'marico',\n",
       "  'detras',\n",
       "  'de',\n",
       "  'un',\n",
       "  'user',\n",
       "  'femenino',\n",
       "  'chavista',\n",
       "  'colaborador'],\n",
       " ['mejor',\n",
       "  'callate',\n",
       "  'cara',\n",
       "  'de',\n",
       "  'puta',\n",
       "  'o',\n",
       "  'reputa',\n",
       "  'como',\n",
       "  'tu',\n",
       "  'madre',\n",
       "  'se',\n",
       "  'nota',\n",
       "  'que',\n",
       "  'te',\n",
       "  'hacen',\n",
       "  'falta',\n",
       "  'estos'],\n",
       " ['cállate', 'puta'],\n",
       " ['callate', 'puta'],\n",
       " ['y',\n",
       "  'el',\n",
       "  'inmigrante',\n",
       "  'recibe',\n",
       "  'ayuda',\n",
       "  'del',\n",
       "  'rico',\n",
       "  'estado',\n",
       "  'ladrón',\n",
       "  'que',\n",
       "  'se',\n",
       "  'olvida',\n",
       "  'de',\n",
       "  'los',\n",
       "  'nacionales',\n",
       "  'mientras',\n",
       "  'nos',\n",
       "  'viola',\n",
       "  'y',\n",
       "  'mata',\n",
       "  'pintada',\n",
       "  'con',\n",
       "  'una',\n",
       "  'verdad',\n",
       "  'a',\n",
       "  'medias'],\n",
       " ['de',\n",
       "  'los',\n",
       "  'moros',\n",
       "  'no',\n",
       "  'se',\n",
       "  'puede',\n",
       "  'esperar',\n",
       "  'nada',\n",
       "  'bueno',\n",
       "  'y',\n",
       "  'esto',\n",
       "  'te',\n",
       "  'lo',\n",
       "  'dicen',\n",
       "  'los',\n",
       "  'propios',\n",
       "  'árabes',\n",
       "  'que',\n",
       "  'también',\n",
       "  'han',\n",
       "  'luchado',\n",
       "  'contra',\n",
       "  'ellos'],\n",
       " ['por',\n",
       "  'que',\n",
       "  'si',\n",
       "  'a',\n",
       "  'una',\n",
       "  'mujer',\n",
       "  'le',\n",
       "  'pegan',\n",
       "  'un',\n",
       "  'tiro',\n",
       "  'en',\n",
       "  'la',\n",
       "  'cabeza',\n",
       "  'dura',\n",
       "  'tres',\n",
       "  'dias',\n",
       "  'en',\n",
       "  'morirse',\n",
       "  'porque',\n",
       "  'a',\n",
       "  'los',\n",
       "  'tres',\n",
       "  'dias',\n",
       "  'la',\n",
       "  'bala',\n",
       "  'encuentra',\n",
       "  'el',\n",
       "  'cerebro'],\n",
       " ['analicemos',\n",
       "  'esto',\n",
       "  'si',\n",
       "  'te',\n",
       "  'pones',\n",
       "  'unos',\n",
       "  'shorts',\n",
       "  'así',\n",
       "  'en',\n",
       "  'la',\n",
       "  'calle',\n",
       "  'qué',\n",
       "  'esperas',\n",
       "  'que',\n",
       "  'te',\n",
       "  'digan',\n",
       "  'acoso',\n",
       "  'o',\n",
       "  'provocación'],\n",
       " ['see',\n",
       "  'tal',\n",
       "  'vez',\n",
       "  'les',\n",
       "  'recordo',\n",
       "  'como',\n",
       "  'peron',\n",
       "  'protegio',\n",
       "  'a',\n",
       "  'eichmann',\n",
       "  'y',\n",
       "  'cientos',\n",
       "  'de',\n",
       "  'nazis',\n",
       "  'o',\n",
       "  'les',\n",
       "  'conto',\n",
       "  'a',\n",
       "  'los',\n",
       "  'arabes',\n",
       "  'el',\n",
       "  'chiste',\n",
       "  'del',\n",
       "  'araba',\n",
       "  'que',\n",
       "  'se',\n",
       "  'lo',\n",
       "  'garcho',\n",
       "  'un',\n",
       "  'camello'],\n",
       " ['pietrapierce',\n",
       "  'story',\n",
       "  'purs',\n",
       "  'sangs',\n",
       "  'arabes',\n",
       "  'stars',\n",
       "  'des',\n",
       "  'festivites',\n",
       "  'a',\n",
       "  'agar',\n",
       "  'el',\n",
       "  'm'],\n",
       " ['qué',\n",
       "  'dice',\n",
       "  'este',\n",
       "  'de',\n",
       "  'frivolizar',\n",
       "  'el',\n",
       "  'acoso',\n",
       "  'escolar',\n",
       "  'por',\n",
       "  'favor',\n",
       "  'queréis',\n",
       "  'dejar',\n",
       "  'de',\n",
       "  'decir',\n",
       "  'semejantes',\n",
       "  'tonterías'],\n",
       " ['retira',\n",
       "  'el',\n",
       "  'permiso',\n",
       "  'a',\n",
       "  'refugiados',\n",
       "  'que',\n",
       "  'fueron',\n",
       "  'de',\n",
       "  'vacaciones',\n",
       "  'a',\n",
       "  'sus',\n",
       "  'países',\n",
       "  'vía'],\n",
       " ['hoy',\n",
       "  'quiero',\n",
       "  'denunciaaaaaaar',\n",
       "  'a',\n",
       "  'la',\n",
       "  'gente',\n",
       "  'puto',\n",
       "  'guarra',\n",
       "  'que',\n",
       "  'huele',\n",
       "  'a',\n",
       "  'sudor',\n",
       "  'y',\n",
       "  'chorizo',\n",
       "  'y',\n",
       "  'se',\n",
       "  'sube',\n",
       "  'al',\n",
       "  'bus',\n",
       "  'dejando',\n",
       "  'a',\n",
       "  'tol',\n",
       "  'mundo',\n",
       "  'ko',\n",
       "  'shame',\n",
       "  'on',\n",
       "  'you'],\n",
       " ['redomicilie',\n",
       "  'su',\n",
       "  'sociedad',\n",
       "  'offshore',\n",
       "  'en',\n",
       "  'emiratos',\n",
       "  'árabes',\n",
       "  'unidos'],\n",
       " ['basta',\n",
       "  'poned',\n",
       "  'pie',\n",
       "  'en',\n",
       "  'pared',\n",
       "  'a',\n",
       "  'tanta',\n",
       "  'provocación',\n",
       "  'y',\n",
       "  'cortad',\n",
       "  'la',\n",
       "  'humillación',\n",
       "  'de',\n",
       "  'estos',\n",
       "  'cuatro',\n",
       "  'hijos',\n",
       "  'de',\n",
       "  'perra'],\n",
       " ['semana',\n",
       "  'de',\n",
       "  'la',\n",
       "  'juventud',\n",
       "  'torneo',\n",
       "  'futbol',\n",
       "  'futbol',\n",
       "  'categoria',\n",
       "  'cadete',\n",
       "  'equipos',\n",
       "  'inscritos',\n",
       "  'los',\n",
       "  'yogurines',\n",
       "  'la',\n",
       "  'elite',\n",
       "  'rayo',\n",
       "  'donbenitense',\n",
       "  'los',\n",
       "  'negratas',\n",
       "  'fuenlabrada',\n",
       "  'minato',\n",
       "  'de',\n",
       "  'kiev',\n",
       "  'los',\n",
       "  'josewifakers',\n",
       "  'voolka'],\n",
       " ['callate', 'y', 'metete', 'party', 'de', 'una', 'puta', 'vez'],\n",
       " ['cuántos',\n",
       "  'inmigrantes',\n",
       "  'creemos',\n",
       "  'que',\n",
       "  'hay',\n",
       "  'y',\n",
       "  'cuántos',\n",
       "  'hay',\n",
       "  'en',\n",
       "  'realidad',\n",
       "  'ciudadanos',\n",
       "  'de',\n",
       "  'un',\n",
       "  'lugar',\n",
       "  'llamado',\n",
       "  'mundo']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_tokenizada=[]\n",
    "\n",
    "for i in range(0,n,1):\n",
    "    tokens = word_tokenize(lista_limpia[i])\n",
    "    lista_tokenizada.append(tokens)\n",
    "lista_tokenizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33108d-855f-4898-a16d-82d8fd19ee4f",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9990057-f614-463c-bc59-276163f9c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish') #Import stop words\n",
    "lista_filtrada=[] #New list where we keep the new data\n",
    "# We We remove the unnecessary words\n",
    "for i in range(0,n,1): #The for loop operates on each of the lists of the list\n",
    "    A=lista_tokenizada[i] #Acces to one list of words\n",
    "    palabras_filtradas = [palabra for palabra in A if palabra not in spanish_stopwords]\n",
    "    lista_filtrada.append(palabras_filtradas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd83dce-3bb0-4258-a752-3297c1fffa55",
   "metadata": {},
   "source": [
    "### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a78c030-5094-48a0-aa9c-dc63ff9bfddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cosa poder pasar mantener inmigracion ilegal españa expulsar él agresión mantero turista poner colau aprieto vía',\n",
       " 'amodio odio perra amigo vida tijerazo',\n",
       " 'callate maldito perra seguro pobre marico detras user femenino chavista colaborador',\n",
       " 'mejor callate cara puta reputa madre nota hacer falta',\n",
       " 'cállate puto',\n",
       " 'callate puto',\n",
       " 'inmigrante recibir ayuda rico ladrón olvidar nacional mientras viola mata pintado verdad medio',\n",
       " 'moro poder esperar bueno decir propio árabe luchado',\n",
       " 'si mujer peguir tiro cabeza durar tres dia morir él tres dia bala encontrar cerebro',\n",
       " 'analicer si pón shorts así calle esperas decir acoso provocación',\n",
       " 'see tal vez recordo peron protegio eichmann ciento nazi conto arab chiste arar garcho camello',\n",
       " 'pietrapiercir story purs sang arab stars des festivit agar m',\n",
       " 'decir frivolizar acoso escolar favor queréis dejar decir semejante tontería',\n",
       " 'retirar permiso refugiado vacación país vía',\n",
       " 'hoy quiero denunciaaaaaaar gente puto guarra oler sudor chorizo subir bus dejar tol mundo ko shame on you',\n",
       " 'redomicilie sociedad offshore emirato árabe unido',\n",
       " 'bastar poned pie pared tanto provocación cortad humillación cuatro hijo perrir',\n",
       " 'semana juventud torneo futbol futbol categoria cadete equipo inscrito yogurín elite rayo donbenitensar negrata fuenlabrado minato kiev josewifakers voolka',\n",
       " 'callate metete party puta vez',\n",
       " 'cuánto inmigrante creer cuánto realidad ciudadano lugar llamado mundo']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_lematizada=[]\n",
    "\n",
    "for i in range(0,n,1):\n",
    "    B=lista_filtrada[i]\n",
    "    lema = nlp(\" \".join(B))\n",
    "    oracion_lematizada = \" \".join([token.lemma_ for token in lema])\n",
    "    lista_lematizada.append(oracion_lematizada)\n",
    "lista_lematizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d08ba-3bff-4982-8a0d-53e1b16209f4",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2736fdd5-dde2-48d7-ad8d-01d1db87f66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<1x16 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 16 stored elements in Compressed Sparse Row format>,\n",
       " <1x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6 stored elements in Compressed Sparse Row format>,\n",
       " <1x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 11 stored elements in Compressed Sparse Row format>,\n",
       " <1x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " <1x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2 stored elements in Compressed Sparse Row format>,\n",
       " <1x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2 stored elements in Compressed Sparse Row format>,\n",
       " <1x13 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 13 stored elements in Compressed Sparse Row format>,\n",
       " <1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 8 stored elements in Compressed Sparse Row format>,\n",
       " <1x13 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 13 stored elements in Compressed Sparse Row format>,\n",
       " <1x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 10 stored elements in Compressed Sparse Row format>,\n",
       " <1x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 15 stored elements in Compressed Sparse Row format>,\n",
       " <1x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " <1x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " <1x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6 stored elements in Compressed Sparse Row format>,\n",
       " <1x18 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 18 stored elements in Compressed Sparse Row format>,\n",
       " <1x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6 stored elements in Compressed Sparse Row format>,\n",
       " <1x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 11 stored elements in Compressed Sparse Row format>,\n",
       " <1x18 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 18 stored elements in Compressed Sparse Row format>,\n",
       " <1x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 5 stored elements in Compressed Sparse Row format>,\n",
       " <1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 8 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_vocabulario=[]\n",
    "VECTORES1=[]\n",
    "#Extract class\n",
    "for i in range(0,n,1):\n",
    "    C=lista_lematizada[i]\n",
    "    vectorizador = CountVectorizer()\n",
    "    vectores = vectorizador.fit_transform([C])\n",
    "    VECTORES1.append(vectores)\n",
    "    vocabulario = vectorizador.get_feature_names_out()\n",
    "    lista_vocabulario.append(vocabulario)\n",
    "lista_vocabulario\n",
    "VECTORES1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c90384-68b0-460a-8cd3-82becb828de8",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c71ef6ab-76b1-4e20-adbb-5dd1c25e1348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración de entrada: ESAS COSAS Y OTRAS PUEDEN PASAR POR MANTENER A LA INMIGRACION ILEGAL EN ESPAÑA Y NO EXPULSARLOS ¿NO? - La agresión de los manteros a un turista pone a Colau en un aprieto https://t.co/C7mZWXAl9P vía @Elperiodico\n",
      "Oración lematizada: esas cosas y otras pueden pasar por mantener a la inmigracion ilegal en españa y no expulsarlos no  la agresión de los manteros a un turista pone a colau en un aprieto  vía \n",
      "Bag of Words: ['agresión' 'aprieto' 'colau' 'cosa' 'españa' 'expulsar' 'ilegal'\n",
      " 'inmigracion' 'mantener' 'mantero' 'pasar' 'poder' 'poner' 'turista'\n",
      " 'vía' 'él']\n",
      "Vectores Bag of Words: [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1]],\n",
       " [[1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 2, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1]],\n",
       " [[1, 1, 2, 1, 1, 1, 1, 1]]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Oración de entrada:\", df.iloc[0,0])\n",
    "print(\"Oración lematizada:\", lista_limpia[0])\n",
    "print(\"Bag of Words:\",lista_vocabulario[0]) \n",
    "print(\"Vectores Bag of Words:\", VECTORES1[0].toarray())\n",
    "lista_vector=[]\n",
    "#Vectorize the class\n",
    "m=len(VECTORES1)\n",
    "for i in range(0,m,1):\n",
    "    A=VECTORES1[i].toarray()\n",
    "    lista_vector.append(A)\n",
    "lista_vector\n",
    "#Convert arrays in list\n",
    "lista_vectorizada=[]\n",
    "for i in range(0,m,1):\n",
    "    A=lista_vector[i].tolist()\n",
    "    lista_vectorizada.append(A)\n",
    "lista_vectorizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b9bcd-1d1c-443b-b06a-8551bdee0af7",
   "metadata": {},
   "source": [
    "### Construir Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0c552894-bc08-4397-8982-3cb8df82052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[agresión, aprieto, colau, cosa, españa, expul...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[amigo, amodio, odio, perra, tijerazo, vida]</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[callate, chavista, colaborador, detras, femen...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[callate, cara, falta, hacer, madre, mejor, no...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cállate, puto]</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[callate, puto]</td>\n",
       "      <td>[[1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ayuda, inmigrante, ladrón, mata, medio, mient...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[bueno, decir, esperar, luchado, moro, poder, ...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[bala, cabeza, cerebro, dia, durar, encontrar,...</td>\n",
       "      <td>[[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[acoso, analicer, así, calle, decir, esperas, ...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[arab, arar, camello, chiste, ciento, conto, e...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[agar, arab, des, festivit, pietrapiercir, pur...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[acoso, decir, dejar, escolar, favor, frivoliz...</td>\n",
       "      <td>[[1, 2, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[país, permiso, refugiado, retirar, vacación, ...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[bus, chorizo, dejar, denunciaaaaaaar, gente, ...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[emirato, offshore, redomicilie, sociedad, uni...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[bastar, cortad, cuatro, hijo, humillación, pa...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[cadete, categoria, donbenitensar, elite, equi...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[callate, metete, party, puta, vez]</td>\n",
       "      <td>[[1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[ciudadano, creer, cuánto, inmigrante, llamado...</td>\n",
       "      <td>[[1, 1, 2, 1, 1, 1, 1, 1]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets  \\\n",
       "0   [agresión, aprieto, colau, cosa, españa, expul...   \n",
       "1        [amigo, amodio, odio, perra, tijerazo, vida]   \n",
       "2   [callate, chavista, colaborador, detras, femen...   \n",
       "3   [callate, cara, falta, hacer, madre, mejor, no...   \n",
       "4                                     [cállate, puto]   \n",
       "5                                     [callate, puto]   \n",
       "6   [ayuda, inmigrante, ladrón, mata, medio, mient...   \n",
       "7   [bueno, decir, esperar, luchado, moro, poder, ...   \n",
       "8   [bala, cabeza, cerebro, dia, durar, encontrar,...   \n",
       "9   [acoso, analicer, así, calle, decir, esperas, ...   \n",
       "10  [arab, arar, camello, chiste, ciento, conto, e...   \n",
       "11  [agar, arab, des, festivit, pietrapiercir, pur...   \n",
       "12  [acoso, decir, dejar, escolar, favor, frivoliz...   \n",
       "13  [país, permiso, refugiado, retirar, vacación, ...   \n",
       "14  [bus, chorizo, dejar, denunciaaaaaaar, gente, ...   \n",
       "15  [emirato, offshore, redomicilie, sociedad, uni...   \n",
       "16  [bastar, cortad, cuatro, hijo, humillación, pa...   \n",
       "17  [cadete, categoria, donbenitensar, elite, equi...   \n",
       "18                [callate, metete, party, puta, vez]   \n",
       "19  [ciudadano, creer, cuánto, inmigrante, llamado...   \n",
       "\n",
       "                                                clase  \n",
       "0   [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "1                                [[1, 1, 1, 1, 1, 1]]  \n",
       "2                 [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "3                       [[1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "4                                            [[1, 1]]  \n",
       "5                                            [[1, 1]]  \n",
       "6           [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "7                          [[1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "8           [[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1]]  \n",
       "9                    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "10    [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "11                      [[1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "12                      [[1, 2, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "13                               [[1, 1, 1, 1, 1, 1]]  \n",
       "14  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "15                               [[1, 1, 1, 1, 1, 1]]  \n",
       "16                [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]  \n",
       "17  [[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "18                                  [[1, 1, 1, 1, 1]]  \n",
       "19                         [[1, 1, 2, 1, 1, 1, 1, 1]]  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1={'tweets':lista_vocabulario,'clase':lista_vectorizada}\n",
    "df_limpio1=pd.DataFrame(data1)\n",
    "df_limpio1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b21bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
